#Arguments needed to create proper paths to everything
scenario: MaterialTransport #name of the folder inside scenarios
model_config_file: qmix_rnn.json #The config file from sacred for the model
model_file: qmix_rnn_unaware.th #The saved model weights
actor_file: rnn_agent #The file the actor model architecture lives in
actor_class: RNNAgent #The class the actor model architecture is in
env_file: MaterialTransport #The .py file this environment is in
env_class: MaterialTransport #This needs to have all of the functionalities of a gym to work

#Arguments needed by main, will not affect training
n_actions: 5 #The number of actions available for the agent
n_inputs: 18
episodes: 500 #Number of episodes to run for
shared_reward: False #Purely for evaluation information
eval_dir: eval
save_eval_output: True

# seed: 0 #sets the seed. Set to -1 to use a random seed.
seed: 76 # eval seed

#Arguments neeeded for most scenarios
n_agents: 4 #Number of agents to run
show_figure_frequency: -1 #Set to -1 to turn off figures. Needs to be 1 when submitting to Robotarium
real_time: False #Set to true for debugging only
max_episode_steps: 70 #maximum number of steps an episode can take
update_frequency: 74 #How often new actions are given to the robotarium
start_dist: .3 #Minimum distance the agents start from each other
robotarium: False #Should be False during training to speed up robots, needs to be true when submitting
barrier_certificate: safe #Can be safe or default for strong or weak barrier certificates
penalize_violations: True #If true, agents get a negative reward for collisions or boundary infractions and the episode stops
LEFT: -1.40 #Minimum x coordinate the robots are allowed to navigate to and start at
RIGHT: 1.40 #Maxiumum x coordinate the robots are allowed to navigate to and start at
UP: -0.9 #Minimum y coordinate the robots are allowed to navigate to and start at
DOWN: 0.9 #Maxiumum y coordinate the robots are allowed to navigate to and start at
enable_logging: True # Uses tensorflow summary writer to log results
device: "/cpu:0" # Specify the device for logger
save_gif: False # Save the gif; Note: Make sure to set show_figure_frequency
gif_frequency: 29 # Frequency at which frames need to be saved for gif creation

#Arguments needed by this scenario
n_fast_agents: 2
n_slow_agents: 2
fast_step: [.4, .45, .5, .55, .6] 
slow_step: [.1, .15, .2, .25, .3]
large_torque: [14, 16, 18, 20, 22]
small_torque: [4, 6, 8, 10, 12]
unload_multiplier: .075
load_multiplier: .025
end_goal_width: .5
time_penalty: -0.1
capability_aware: False #Whether or not the agents know their own capabilities. Should probably not use ids if this is true
zone1_radius: .35
zone1:
  distribution: 'normal'
  loc: 75
  scale: 10
zone2:
  distribution: 'normal'
  loc: 15
  scale: 4
power_decay: False
decay_rate: 0.99
motor_failure: False
